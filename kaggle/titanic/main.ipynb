{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roseh\\Desktop\\study\\deep_learning\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\Users\\roseh\\Desktop\\study\\deep_learning\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\Users\\roseh\\Desktop\\study\\deep_learning\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\Users\\roseh\\Desktop\\study\\deep_learning\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\Users\\roseh\\Desktop\\study\\deep_learning\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\Users\\roseh\\Desktop\\study\\deep_learning\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\roseh\\Desktop\\study\\deep_learning\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\Users\\roseh\\Desktop\\study\\deep_learning\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch: 0001, Cost: 0.000000000\n",
      "Epoch: 0002, Cost: 0.000000000\n",
      "Epoch: 0003, Cost: 0.000000000\n",
      "Epoch: 0004, Cost: 0.000000000\n",
      "Epoch: 0005, Cost: 0.000000000\n",
      "Epoch: 0006, Cost: 0.000000000\n",
      "Epoch: 0007, Cost: 0.000000000\n",
      "Epoch: 0008, Cost: 0.000000000\n",
      "Epoch: 0009, Cost: 0.000000000\n",
      "Epoch: 0010, Cost: 0.000000000\n",
      "Epoch: 0011, Cost: 0.000000000\n",
      "Epoch: 0012, Cost: 0.000000000\n",
      "Epoch: 0013, Cost: 0.000000000\n",
      "Epoch: 0014, Cost: 0.000000000\n",
      "Epoch: 0015, Cost: 0.000000000\n",
      "Epoch: 0016, Cost: 0.000000000\n",
      "Epoch: 0017, Cost: 0.000000000\n",
      "Epoch: 0018, Cost: 0.000000000\n",
      "Epoch: 0019, Cost: 0.000000000\n",
      "Epoch: 0020, Cost: 0.000000000\n",
      "Epoch: 0021, Cost: 0.000000000\n",
      "Epoch: 0022, Cost: 0.000000000\n",
      "Epoch: 0023, Cost: 0.000000000\n",
      "Epoch: 0024, Cost: 0.000000000\n",
      "Epoch: 0025, Cost: 0.000000000\n",
      "Epoch: 0026, Cost: 0.000000000\n",
      "Epoch: 0027, Cost: 0.000000000\n",
      "Epoch: 0028, Cost: 0.000000000\n",
      "Epoch: 0029, Cost: 0.000000000\n",
      "Epoch: 0030, Cost: 0.000000000\n",
      "Epoch: 0031, Cost: 0.000000000\n",
      "Epoch: 0032, Cost: 0.000000000\n",
      "Epoch: 0033, Cost: 0.000000000\n",
      "Epoch: 0034, Cost: 0.000000000\n",
      "Epoch: 0035, Cost: 0.000000000\n",
      "Epoch: 0036, Cost: 0.000000000\n",
      "Epoch: 0037, Cost: 0.000000000\n",
      "Epoch: 0038, Cost: 0.000000000\n",
      "Epoch: 0039, Cost: 0.000000000\n",
      "Epoch: 0040, Cost: 0.000000000\n",
      "Epoch: 0041, Cost: 0.000000000\n",
      "Epoch: 0042, Cost: 0.000000000\n",
      "Epoch: 0043, Cost: 0.000000000\n",
      "Epoch: 0044, Cost: 0.000000000\n",
      "Epoch: 0045, Cost: 0.000000000\n",
      "Epoch: 0046, Cost: 0.000000000\n",
      "Epoch: 0047, Cost: 0.000000000\n",
      "Epoch: 0048, Cost: 0.000000000\n",
      "Epoch: 0049, Cost: 0.000000000\n",
      "Epoch: 0050, Cost: 0.000000000\n",
      "Epoch: 0051, Cost: 0.000000000\n",
      "Epoch: 0052, Cost: 0.000000000\n",
      "Epoch: 0053, Cost: 0.000000000\n",
      "Epoch: 0054, Cost: 0.000000000\n",
      "Epoch: 0055, Cost: 0.000000000\n",
      "Epoch: 0056, Cost: 0.000000000\n",
      "Epoch: 0057, Cost: 0.000000000\n",
      "Epoch: 0058, Cost: 0.000000000\n",
      "Epoch: 0059, Cost: 0.000000000\n",
      "Epoch: 0060, Cost: 0.000000000\n",
      "Epoch: 0061, Cost: 0.000000000\n",
      "Epoch: 0062, Cost: 0.000000000\n",
      "Epoch: 0063, Cost: 0.000000000\n",
      "Epoch: 0064, Cost: 0.000000000\n",
      "Epoch: 0065, Cost: 0.000000000\n",
      "Epoch: 0066, Cost: 0.000000000\n",
      "Epoch: 0067, Cost: 0.000000000\n",
      "Epoch: 0068, Cost: 0.000000000\n",
      "Epoch: 0069, Cost: 0.000000000\n",
      "Epoch: 0070, Cost: 0.000000000\n",
      "Epoch: 0071, Cost: 0.000000000\n",
      "Epoch: 0072, Cost: 0.000000000\n",
      "Epoch: 0073, Cost: 0.000000000\n",
      "Epoch: 0074, Cost: 0.000000000\n",
      "Epoch: 0075, Cost: 0.000000000\n",
      "Epoch: 0076, Cost: 0.000000000\n",
      "Epoch: 0077, Cost: 0.000000000\n",
      "Epoch: 0078, Cost: 0.000000000\n",
      "Epoch: 0079, Cost: 0.000000000\n",
      "Epoch: 0080, Cost: 0.000000000\n",
      "Epoch: 0081, Cost: 0.000000000\n",
      "Epoch: 0082, Cost: 0.000000000\n",
      "Epoch: 0083, Cost: 0.000000000\n",
      "Epoch: 0084, Cost: 0.000000000\n",
      "Epoch: 0085, Cost: 0.000000000\n",
      "Epoch: 0086, Cost: 0.000000000\n",
      "Epoch: 0087, Cost: 0.000000000\n",
      "Epoch: 0088, Cost: 0.000000000\n",
      "Epoch: 0089, Cost: 0.000000000\n",
      "Epoch: 0090, Cost: 0.000000000\n",
      "Epoch: 0091, Cost: 0.000000000\n",
      "Epoch: 0092, Cost: 0.000000000\n",
      "Epoch: 0093, Cost: 0.000000000\n",
      "Epoch: 0094, Cost: 0.000000000\n",
      "Epoch: 0095, Cost: 0.000000000\n",
      "Epoch: 0096, Cost: 0.000000000\n",
      "Epoch: 0097, Cost: 0.000000000\n",
      "Epoch: 0098, Cost: 0.000000000\n",
      "Epoch: 0099, Cost: 0.000000000\n",
      "Epoch: 0100, Cost: 0.000000000\n",
      "Epoch: 0101, Cost: 0.000000000\n",
      "Epoch: 0102, Cost: 0.000000000\n",
      "Epoch: 0103, Cost: 0.000000000\n",
      "Epoch: 0104, Cost: 0.000000000\n",
      "Epoch: 0105, Cost: 0.000000000\n",
      "Epoch: 0106, Cost: 0.000000000\n",
      "Epoch: 0107, Cost: 0.000000000\n",
      "Epoch: 0108, Cost: 0.000000000\n",
      "Epoch: 0109, Cost: 0.000000000\n",
      "Epoch: 0110, Cost: 0.000000000\n",
      "Epoch: 0111, Cost: 0.000000000\n",
      "Epoch: 0112, Cost: 0.000000000\n",
      "Epoch: 0113, Cost: 0.000000000\n",
      "Epoch: 0114, Cost: 0.000000000\n",
      "Epoch: 0115, Cost: 0.000000000\n",
      "Epoch: 0116, Cost: 0.000000000\n",
      "Epoch: 0117, Cost: 0.000000000\n",
      "Epoch: 0118, Cost: 0.000000000\n",
      "Epoch: 0119, Cost: 0.000000000\n",
      "Epoch: 0120, Cost: 0.000000000\n",
      "Epoch: 0121, Cost: 0.000000000\n",
      "Epoch: 0122, Cost: 0.000000000\n",
      "Epoch: 0123, Cost: 0.000000000\n",
      "Epoch: 0124, Cost: 0.000000000\n",
      "Epoch: 0125, Cost: 0.000000000\n",
      "Epoch: 0126, Cost: 0.000000000\n",
      "Epoch: 0127, Cost: 0.000000000\n",
      "Epoch: 0128, Cost: 0.000000000\n",
      "Epoch: 0129, Cost: 0.000000000\n",
      "Epoch: 0130, Cost: 0.000000000\n",
      "Epoch: 0131, Cost: 0.000000000\n",
      "Epoch: 0132, Cost: 0.000000000\n",
      "Epoch: 0133, Cost: 0.000000000\n",
      "Epoch: 0134, Cost: 0.000000000\n",
      "Epoch: 0135, Cost: 0.000000000\n",
      "Epoch: 0136, Cost: 0.000000000\n",
      "Epoch: 0137, Cost: 0.000000000\n",
      "Epoch: 0138, Cost: 0.000000000\n",
      "Epoch: 0139, Cost: 0.000000000\n",
      "Epoch: 0140, Cost: 0.000000000\n",
      "Epoch: 0141, Cost: 0.000000000\n",
      "Epoch: 0142, Cost: 0.000000000\n",
      "Epoch: 0143, Cost: 0.000000000\n",
      "Epoch: 0144, Cost: 0.000000000\n",
      "Epoch: 0145, Cost: 0.000000000\n",
      "Epoch: 0146, Cost: 0.000000000\n",
      "Epoch: 0147, Cost: 0.000000000\n",
      "Epoch: 0148, Cost: 0.000000000\n",
      "Epoch: 0149, Cost: 0.000000000\n",
      "Epoch: 0150, Cost: 0.000000000\n"
     ]
    }
   ],
   "source": [
    "# xy = np.loadtxt('train.csv', delimiter=',', dtype=np.int32)\n",
    "test_data = pd.read_csv('test.csv')\n",
    "xy = pd.read_csv('train.csv')\n",
    "\n",
    "test_data.head()\n",
    "\n",
    "y_data = xy[['Survived']] #열 1개만 불러올 때는 이런 식으로 불러와야 shape이 깨지지 않음\n",
    "# y_data = xy.drop(['PassengerId','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked'], axis=1)\n",
    "x_data_1 = xy.drop(['Survived', 'PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked','Fare'],axis=1)\n",
    "x_data_2 = xy.drop(['Survived', 'PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'],axis=1)\n",
    "x_data_1['Age'].fillna(x_data_1['Age'].mean(), inplace=True)\n",
    "\n",
    "X=tf.placeholder(tf.float32, shape=[None,4]) #watch out for data shape!\n",
    "Y=tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "W=tf.Variable(tf.random_normal([4,1], name='weight'))\n",
    "b=tf.Variable(tf.random_normal([1], name='bias'))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost) #we dont have to calculate!\n",
    "\n",
    "predicted = tf.cast(hypothesis>0.5, dtype=tf.float32) #cast means divide to 0 or 1\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y), dtype=tf.float32))\n",
    "\n",
    "training_epochs = 150\n",
    "batch_size = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    total_batch = int(len(x_data_1) / batch_size)\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs = x_data_1[i * batch_size:(i + 1) * batch_size]\n",
    "            batch_ys = y_data[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "            c, _ = sess.run([cost, train], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print(\"Epoch: {:04d}, Cost: {:.9f}\".format(epoch + 1, avg_cost))\n",
    "\n",
    "        h, p, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data_1, Y: y_data})\n",
    "        # print(\"\\nHypothesis: \", h, \"\\nPredicted (Y): \", p, \"\\nAccuracy: \", a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
